import argparse
import copy 
import math 
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn import svm
from sklearn.metrics import precision_recall_curve, auc, roc_auc_score
from sklearn.preprocessing import StandardScaler
from sqlalchemy import create_engine

def load_data():
    '''
    The raw data are generated by running 
     "taosBenchmark -I stmt -n 200 -t 100" in terminal.
    A database test and a supertable meters are created, containing 20,000 X 3 time series samples
    '''
    engine = create_engine("taosrest://root:taosdata@localhost:6041")
    df = pd.read_sql("SELECT * FROM test.meters", engine)
    return df

def add_abnomal_data(df_raw, SNR, percentage):
    '''
    Artifically add some noise on raw data.
    1. Randomly choose percentage% row to add noise
    2. Generate the seed nosiy sample 'noise' for  'current', 'voltage','phase'
    3. For the selected value(row, :) += Noise(SNR, noise)
    '''
    label = [np.random.uniform()<percentage for i in range(df_raw.shape[0])]
    label = list(map(lambda x: -1 if x else 1, label))
    df_raw['label'] = label
    df_noisy = df_raw.copy()
    df3 = df_noisy.loc[df_noisy['label'] == -1,['current', 'voltage','phase']]

    noise = np.random.randn(df3.shape[0],df3.shape[1]) 	#产生N(0,1)噪声数据
    noise = noise-np.mean(noise)     							    #均值为0
    signal_power = np.linalg.norm( df3 - df3.mean() )**2 / df3.size	#此处是信号的std**2
    noise_variance = signal_power/np.power(10,(SNR/10))         #此处是噪声的std**2
    noise = (np.sqrt(noise_variance) / np.std(noise) )*noise    ##此处是噪声的std**2
    mean = np.mean(df3.to_numpy(),axis=0)
    mean = mean.reshape((1,3))
    noise = noise + np.repeat(mean*0.1, noise.shape[0], axis=0)
    df3 = noise + df3

    df_noisy.loc[df_noisy['label'] == -1,['current', 'voltage','phase']] = df3
    return df_noisy

def get_statistics(df_raw, df_noisy):
    '''
    Choose California.SanDiego as a representative example
    Plot three figures for one feature each, showing both raw data and raw+noisy data
    '''
    df_raw = df_raw[df_raw['location'] == "California.SanFrancisco"]
    df_raw = df_raw[['current', 'voltage','phase']]
    df_noisy = df_noisy[df_noisy['location'] == "California.SanFrancisco"]
    df_noisy = df_noisy[['current', 'voltage','phase']]
    df_raw = df_raw.reset_index()
    df_noisy = df_noisy.reset_index()
    # df_noisy.to_csv("df_ca_sfo.csv")

    stat_raw = {'min':df_raw.min().round(2), 'max':df_raw.max().round(2), 'mean': df_raw.mean().round(2)}
    stat_noisy = {'min':df_noisy.min().round(2), 'max':df_noisy.max().round(2), 'mean': df_noisy.mean().round(2)}

    fig = plt.figure(figsize=(20,10))
    ax1 = fig.add_subplot(3,1,1)
    ax2 = fig.add_subplot(3,1,2)
    ax3 = fig.add_subplot(3,1,3)
    df_noisy['current'].plot(ax = ax1, marker = 's', color = 'g')
    df_raw['current'].plot(ax = ax1, marker = '*', color = 'r',
        title = "current: raw(min={}, max={}, mean={}), noisy(min={}, max={}, mean={})"
        .format(stat_raw['min']['current'], stat_raw['max']['current'], stat_raw['mean']['current'],
            stat_noisy['min']['current'], stat_noisy['max']['current'], stat_noisy['mean']['current']))
    
    df_noisy['voltage'].plot(ax = ax2, marker = 's', color = 'g')
    df_raw['voltage'].plot(ax = ax2, marker = '*', color = 'r',
        title = "voltage: raw(min={}, max={}, mean={}), noisy(min={}, max={}, mean={})"
        .format(stat_raw['min']['voltage'], stat_raw['max']['voltage'], stat_raw['mean']['voltage'],
        stat_noisy['min']['voltage'], stat_noisy['max']['voltage'], stat_noisy['mean']['voltage']))
    
    df_noisy['phase'].plot(ax = ax3, marker = 's', color = 'g')
    df_raw['phase'].plot(ax = ax3, marker = '*', color = 'r',
        title = "phase: raw(min={}, max={}, mean={}), noisy(min={}, max={}, mean={})"
        .format(stat_raw['min']['phase'], stat_raw['max']['phase'], stat_raw['mean']['phase'],
        stat_noisy['min']['phase'], stat_noisy['max']['phase'], stat_noisy['mean']['phase']))

    plt.savefig('df_raw_noisy.png',bbox_inches ="tight")

def split_data(df_noisy, ratio):
    '''
    For each tag, split it as training and test data by ratio(train.shape[0] / test.shape[0]), according to time stamp
    '''
    train = {}
    test = {}

    tags = df_noisy['groupid'].unique()
    for t in tags:
        temp = df_noisy[df_noisy['groupid'] == t]
        n = temp.shape[0]
        ntrain = math.floor(n * ratio)
        train_tag = temp.iloc[0:ntrain]
        test_tag = temp.iloc[ntrain:n]
        train_tag = train_tag.reset_index()
        test_tag = test_tag.reset_index()
        train[t] = train_tag
        test[t] = test_tag
        # print("tag={}, n = {}, train.shape = {}, test.shape = {}".format(t, n, train[t].shape, test[t].shape))
    return (train, test)
   
def abnormal_detection(train, test, nu):
    '''
    Use train data to fit one class SVM model
    Use test data to evelaute the trained model
    '''
    frames = []
    for key in train.keys():
        frames.append(train[key])
    train_x = pd.concat(frames)
    train_x = train_x.loc[train_x['label'] == 1]
    train_x = train_x.reset_index()
    train_y = train_x['label'].values
    train_x = train_x[['current', 'voltage','phase']].values
    # # train with nu
    clf = svm.OneClassSVM(nu=nu, kernel='rbf', gamma='auto')
    scaler = StandardScaler().fit(train_x)
    train_x = scaler.transform(train_x)
    clf.fit(train_x)
    result = {}
    for key in sorted(test.keys()):
        test_x = test[key][['current', 'voltage','phase']].values
        test_y = test[key][['label']].values
        print('goupid = {}, test_x.shape = {}'.format(key, test_x.shape))
        test_x = scaler.transform(test_x)
        ypred_test = clf.predict(test_x)
        error = 1- float(sum(list(map(lambda x,y: 1 if x==y else 0, test_y,ypred_test)))/len(test_y))
        test[key]['pred'] = ypred_test
        result[key] = {'error': error}
        test[key].to_csv('goupid{}.csv'.format(key))
    return result

def parse_args():
    parser = argparse.ArgumentParser(description='Anomaly Detection by One Class SVM')
    parser.add_argument('--rate_train_test', default=0.8, type=float, help='rate of splitting train and test data')
    parser.add_argument('--rate_abnormal_normal', default=0.05, type=float, help='rate of abnormal data versus normal data.')
    parser.add_argument('--variance_abnormal_data', default=10, type=float, help='SNR setting.')
    parser.add_argument('--nu', default=0.05, type=float, help='OneClass SVM hyperparameter nu.')
    args = parser.parse_args()
    return args

def main():
    args = parse_args()
    rate_train_test = args.rate_train_test
    rate_abnormal_normal = args.rate_abnormal_normal
    variance_abnormal_data = args.variance_abnormal_data
    nu = args.nu

    df_raw = load_data()
    df_noisy = add_abnomal_data(df_raw, variance_abnormal_data, rate_abnormal_normal)
    # df_raw.to_csv('df_raw.csv')
    # df_noisy.to_csv("df_noisy.csv")
    get_statistics(df_raw, df_noisy)
    train, test = split_data(df_noisy, rate_train_test)
    result = abnormal_detection(train, test, nu)
    print(result)

if __name__ == "__main__":
    main()


